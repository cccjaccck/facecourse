{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyline(im, landmarks, start, end, isClosed=False) :\n",
    "    points = []\n",
    "    for i in range(start, end+1) :\n",
    "        point = [landmarks.part(i).x, landmarks.part(i).y]\n",
    "        points.append(point)\n",
    "        \n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    cv2.polylines(im, [points], isClosed, (255, 200, 0),\n",
    "                 thickness=2, lineType=cv2.LINE_8)\n",
    "    \n",
    "\n",
    "# Use this function for 70-poinst facial lanmark detector model\n",
    "def renderFace(im, landmarks) :\n",
    "    assert(landmarks.num_parts == 68)\n",
    "    drawPolyline(im, landmarks, 0, 16)              # Jaw line\n",
    "    drawPolyline(im, landmarks, 17, 21)             # Left eyebrow\n",
    "    drawPolyline(im, landmarks, 22, 26)             # Right eyebrow\n",
    "    drawPolyline(im, landmarks, 27, 30)             # NOse bridge \n",
    "    drawPolyline(im, landmarks, 30, 35, True)       # Lower nose\n",
    "    drawPolyline(im, landmarks, 36, 41, True)       # Left eye\n",
    "    drawPolyline(im, landmarks, 42, 47, True)       # Right eye\n",
    "    drawPolyline(im, landmarks, 48, 59, True)       # Outer LIp\n",
    "    drawPolyline(im, landmarks, 60, 67, True)       # Inner lip\n",
    "\n",
    "    \n",
    "# Ues this funciton for any model other than \n",
    "# 70 points facial_landmark detctor model\n",
    "def renderFace2(im, landmarks, color=(0, 255, 0), radius=3):\n",
    "    for p in landmarks.parts() :\n",
    "        cv2.circle(im, (p.x, p.y), radius, color, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"Facial Landmark dectector\", im1)\n",
    "cv2.imshow(\"Facial Landmark dectector\", im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces 1 dectected:  1\n",
      "Number of faces 2 dectected:  1\n",
      "Number of landmarks 1 :  68\n",
      "Number of landmarks 2 :  68\n"
     ]
    }
   ],
   "source": [
    "import dlib, cv2\n",
    "import numpy as np\n",
    "# from renderFace import renderFace\n",
    "\n",
    "def writeLandmarksToFile(landmarks, landmarksFileName) :\n",
    "    with open(landmarksFileName, 'w') as f:\n",
    "        for p in landmarks.parts() :\n",
    "            f.write(\"%s %s\\n\" %(int(p.x), int(p.y)))\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "def appendLandmarksToList(landmarks, arr) :\n",
    "    for p in landmarks.parts() :\n",
    "        arr.append((int(p.x), int(p.y)))\n",
    "    \n",
    "\n",
    "    \n",
    "# Landmark model location\n",
    "PREDICTOR_PATH = \"./models/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Get the face detector\n",
    "faceDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# The landmark detector is implemented in the shape_predictor class\n",
    "landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "    \n",
    "    \n",
    "# Read image\n",
    "imageFilename1 = \"./data/images/rapunzel.jpg\"\n",
    "imageFilename2 = \"./data/images/seoyoung.jpg\"\n",
    "im1 = cv2.imread(imageFilename1)\n",
    "# im2 = im1[:, int(im1.shape[1]/2) :]\n",
    "# im1 = im1[:, :int(im1.shape[1]/2)]\n",
    "im2 = cv2.imread(imageFilename2)\n",
    "im1 = cv2.resize(im1, (600, 600))\n",
    "im2 = cv2.resize(im2, (600, 600))\n",
    "# im1 = cv2.flip(im1, 1)\n",
    "# im2 = cv2.flip(im2, 1)\n",
    "\n",
    "# Detect faces in the image\n",
    "faceRects1 = faceDetector(im1, 0)\n",
    "faceRects2 = faceDetector(im2, 0)\n",
    "print(\"Number of faces 1 dectected: \", len(faceRects1))\n",
    "print(\"Number of faces 2 dectected: \", len(faceRects2))\n",
    "\n",
    "# List to store landmarks of all detected faces\n",
    "landmarksAll1 = []\n",
    "landmarksAll2 = []\n",
    "\n",
    "# 랜드마크 찾기\n",
    "# Loop over all detected face rectangles\n",
    "for i in range(0, len(faceRects1)) :\n",
    "    newRect1 = dlib.rectangle(int(faceRects1[i].left()),\n",
    "                            int(faceRects1[i].top()),\n",
    "                            int(faceRects1[i].right()),\n",
    "                            int(faceRects1[i].bottom()))\n",
    "    newRect2 = dlib.rectangle(int(faceRects2[i].left()),\n",
    "                            int(faceRects2[i].top()),\n",
    "                            int(faceRects2[i].right()),\n",
    "                            int(faceRects2[i].bottom()))\n",
    "    #\n",
    "    # For every face rectangle, run landmarkDectector\n",
    "    landmarks1 = landmarkDetector(im1, newRect1)\n",
    "    landmarks2 = landmarkDetector(im2, newRect2)\n",
    "    # Print number of landmarks\n",
    "    if i==0:\n",
    "        print(\"Number of landmarks 1 : \", len(landmarks1.parts()))\n",
    "        print(\"Number of landmarks 2 : \", len(landmarks1.parts()))\n",
    "        \n",
    "    # Store landmarks for current face\n",
    "    appendLandmarksToList(landmarks1, landmarksAll1)\n",
    "    appendLandmarksToList(landmarks2, landmarksAll2)\n",
    "    \n",
    "#     Draw landmarks on face\n",
    "    renderFace(im1, landmarks1)\n",
    "    renderFace(im2, landmarks2)\n",
    "    \n",
    "#     landmarksFileName = imageFilename + \".txt\"\n",
    "#     print(\"Saving landmarks to\", landmarksFileName)\n",
    "    # Write landmarks to disk\n",
    "#     writeLandmarksToFile(landmarks, landmarksFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputFileName = \"results/t2Landmarks.jpg\"\n",
    "# print(\"Saving output image to\", outputFileName)\n",
    "# cv2.imwrite(outputFileName, im)\n",
    "\n",
    "cv2.imshow(\"Facial Landmark dectector\", im1)\n",
    "cv2.imshow(\"Facial Landmark dectector\", im2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(109, 263),\n",
       " (104, 296),\n",
       " (103, 332),\n",
       " (113, 366),\n",
       " (127, 394),\n",
       " (144, 420),\n",
       " (160, 444),\n",
       " (175, 465),\n",
       " (195, 474),\n",
       " (221, 473),\n",
       " (254, 459),\n",
       " (290, 441),\n",
       " (324, 419),\n",
       " (350, 389),\n",
       " (366, 352),\n",
       " (375, 314),\n",
       " (382, 274),\n",
       " (113, 226),\n",
       " (126, 217),\n",
       " (142, 218),\n",
       " (158, 226),\n",
       " (174, 237),\n",
       " (233, 241),\n",
       " (258, 232),\n",
       " (287, 230),\n",
       " (313, 237),\n",
       " (334, 253),\n",
       " (200, 285),\n",
       " (195, 313),\n",
       " (189, 341),\n",
       " (184, 369),\n",
       " (169, 373),\n",
       " (178, 380),\n",
       " (189, 386),\n",
       " (203, 382),\n",
       " (217, 378),\n",
       " (131, 262),\n",
       " (144, 249),\n",
       " (165, 255),\n",
       " (177, 282),\n",
       " (159, 283),\n",
       " (138, 277),\n",
       " (246, 290),\n",
       " (261, 265),\n",
       " (284, 264),\n",
       " (301, 282),\n",
       " (286, 294),\n",
       " (263, 295),\n",
       " (152, 398),\n",
       " (165, 399),\n",
       " (180, 400),\n",
       " (191, 404),\n",
       " (205, 401),\n",
       " (226, 400),\n",
       " (252, 399),\n",
       " (227, 422),\n",
       " (206, 433),\n",
       " (192, 435),\n",
       " (179, 431),\n",
       " (165, 420),\n",
       " (158, 401),\n",
       " (179, 407),\n",
       " (191, 409),\n",
       " (205, 407),\n",
       " (244, 402),\n",
       " (206, 419),\n",
       " (192, 420),\n",
       " (180, 418)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarksAll1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마우스로 포인트 추가 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클릭 좌표 : 260, 69\n"
     ]
    }
   ],
   "source": [
    "# 귀 가로 끝 > 목 > 왼쪽 어깨 > 오른쪽 어깨 순으로\n",
    "# 1. 마우스 이벤트 발생시 호출될 함수를 정의합니다. \n",
    "def mouse_callback1(event, x, y, flags, param):\n",
    "    l = len(landmarksAll1)\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if (l==70):\n",
    "            x = im1.shape[1] - 1\n",
    "        if (l==71):\n",
    "            x = 0\n",
    "        print(\"클릭 좌표 : %d, %d\"%(x,y))\n",
    "        landmarksAll1.append((x,y))\n",
    "\n",
    "\n",
    "# img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')  # 2. 마우스 이벤트를 감지할 윈도우를 생성합니다.  \n",
    "\n",
    "\n",
    "# 3. 이름이 image인 윈도우에서 마우스 이벤트가 발생하면 mouse_callback 함수가 호출되게 됩니다. \n",
    "cv2.setMouseCallback('image', mouse_callback1)  \n",
    "\n",
    "\n",
    "cv2.imshow('image',im1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2번 사진\n",
    "def mouse_callback2(event, x, y, flags, param):\n",
    "    l = len(landmarksAll2)\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        if (l==70):\n",
    "            x = im2.shape[1] - 1\n",
    "        if (l==71):\n",
    "            x = 0\n",
    "        print(\"클릭 좌표 : %d, %d\"%(x,y))\n",
    "        landmarksAll2.append((x,y))\n",
    "\n",
    "\n",
    "# img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')  # 2. 마우스 이벤트를 감지할 윈도우를 생성합니다.  \n",
    "\n",
    "\n",
    "# 3. 이름이 image인 윈도우에서 마우스 이벤트가 발생하면 mouse_callback 함수가 호출되게 됩니다. \n",
    "cv2.setMouseCallback('image', mouse_callback2)  \n",
    "\n",
    "\n",
    "cv2.imshow('image',im2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarksAll1), len(landmarksAll2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지의 가장자리 8개 추가 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 2 3 \n",
    "# 8   4\n",
    "# 7 6 5\n",
    "\n",
    "for arr, im in [(landmarksAll1, im1), (landmarksAll2, im2)] :\n",
    "    arr.append((0, 0))\n",
    "    arr.append(((im.shape[1]-1)/2, 0))\n",
    "    arr.append((im.shape[1]-1, 0))\n",
    "    arr.append((im.shape[1]-1, (im.shape[0]-1)/2))\n",
    "    arr.append((im.shape[1]-1, im.shape[0]-1))\n",
    "    arr.append(((im.shape[1]-1)/2, im.shape[0]-1))\n",
    "    arr.append((0, im.shape[0]-1))\n",
    "    arr.append((0, (im.shape[0]-1)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarksAll1), len(landmarksAll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (199.5, 0),\n",
       " (399, 0),\n",
       " (399, 229.5),\n",
       " (399, 459),\n",
       " (199.5, 459),\n",
       " (0, 459),\n",
       " (0, 229.5)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarksAll1[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Read points from text file\n",
    "def readPoints(path) :\n",
    "    # Create an array of points.\n",
    "    points = [];\n",
    "    # Read points\n",
    "    with open(path) as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "    return points\n",
    "\n",
    "# Apply affine transform calculated using srcTri and dstTri to src and\n",
    "# output an image of size.\n",
    "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
    "    \n",
    "    # Given a pair of triangles, find the affine transform.\n",
    "    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
    "    \n",
    "    # Apply the Affine Transform just found to the src image\n",
    "    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def morphTriangle(img1, img2, img, t1, t2, t, alpha) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t]))\n",
    "\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = []\n",
    "    t2Rect = []\n",
    "    tRect = []\n",
    "\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        tRect.append(((t[i][0] - r[0]),(t[i][1] - r[1])))\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r[3], r[2], 3), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(tRect), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    img2Rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]\n",
    "\n",
    "    size = (r[2], r[3])\n",
    "    warpImage1 = applyAffineTransform(img1Rect, t1Rect, tRect, size)\n",
    "    warpImage2 = applyAffineTransform(img2Rect, t2Rect, tRect, size)\n",
    "    \n",
    "\n",
    "    # Alpha blend rectangular patches\n",
    "    imgRect = (1.0 - alpha) * warpImage1 + alpha * warpImage2\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    try :\n",
    "        img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * ( 1 - mask ) + imgRect * mask\n",
    "    except :\n",
    "        print(( 1 - mask ).shape, \"띠띠\")\n",
    "        print(img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]].shape, \"빵빵\")\n",
    "        raise Exception\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point) :\n",
    "    if point[0] < rect[0] :\n",
    "        return False\n",
    "    elif point[1] < rect[1] :\n",
    "        return False\n",
    "    elif point[0] > rect[2] :\n",
    "        return False\n",
    "    elif point[1] > rect[3] :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "    # Create subdiv\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "   \n",
    "    # Insert points into subdiv\n",
    "    for p in points:\n",
    "        subdiv.insert((p[0], p[1]))\n",
    "\n",
    "   \n",
    "    # List of triangles. Each triangle is a list of 3 points ( 6 numbers )\n",
    "    triangleList = subdiv.getTriangleList()\n",
    "\n",
    "    # Find the indices of triangles in the points array\n",
    "\n",
    "    delaunayTri = []\n",
    "    \n",
    "    for t in triangleList:\n",
    "        pt = []\n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])        \n",
    "        \n",
    "        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "            ind = []\n",
    "            for j in range(0, 3):\n",
    "                for k in range(0, len(points)):                    \n",
    "                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "                        ind.append(k)                            \n",
    "            if len(ind) == 3:                                                \n",
    "                delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "        \n",
    "\n",
    "    \n",
    "    return delaunayTri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename1 = './data/images/ben.jpg'\n",
    "# filename2 = './data/images/morgan.jpg'\n",
    "alpha = 0.6\n",
    "\n",
    "# Read images\n",
    "# img1 = cv2.imread(filename1);\n",
    "# img2 = cv2.imread(filename2);\n",
    "img1 = im1\n",
    "img2 = im2\n",
    "\n",
    "# Convert Mat to float data type\n",
    "img1 = np.float32(img1)\n",
    "img2 = np.float32(img2)\n",
    "\n",
    "# Read array of corresponding points\n",
    "#     points1 = readPoints(filename1 + '.txt')\n",
    "#     points2 = readPoints(filename2 + '.txt')\n",
    "points1 = landmarksAll1\n",
    "points2 = landmarksAll2\n",
    "points = [];\n",
    "\n",
    "# Compute weighted average point coordinates\n",
    "for i in range(0, len(points1)):\n",
    "    x = ( 1 - alpha ) * points1[i][0] + alpha * points2[i][0]\n",
    "    y = ( 1 - alpha ) * points1[i][1] + alpha * points2[i][1]\n",
    "    points.append((x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 500, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im2.shape\n",
    "im1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 500, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(18, 37, 17),\n",
       " (37, 18, 19),\n",
       " (2, 75, 1),\n",
       " (75, 2, 3),\n",
       " (0, 75, 17),\n",
       " (75, 0, 1),\n",
       " (21, 27, 39),\n",
       " (27, 21, 22),\n",
       " (75, 68, 17),\n",
       " (1, 0, 36),\n",
       " (46, 54, 47),\n",
       " (54, 46, 13),\n",
       " (75, 3, 74),\n",
       " (2, 1, 41),\n",
       " (32, 49, 31),\n",
       " (49, 32, 50),\n",
       " (74, 4, 5),\n",
       " (4, 74, 3),\n",
       " (3, 2, 31),\n",
       " (54, 13, 12),\n",
       " (73, 74, 7),\n",
       " (4, 3, 31),\n",
       " (67, 62, 66),\n",
       " (62, 67, 61),\n",
       " (74, 5, 6),\n",
       " (5, 4, 48),\n",
       " (61, 51, 62),\n",
       " (51, 61, 50),\n",
       " (74, 6, 7),\n",
       " (6, 5, 59),\n",
       " (51, 33, 52),\n",
       " (33, 51, 50),\n",
       " (7, 6, 58),\n",
       " (40, 28, 29),\n",
       " (28, 40, 39),\n",
       " (73, 7, 8),\n",
       " (8, 7, 57),\n",
       " (10, 73, 9),\n",
       " (73, 10, 11),\n",
       " (9, 73, 8),\n",
       " (9, 8, 56),\n",
       " (11, 72, 73),\n",
       " (72, 11, 12),\n",
       " (10, 9, 55),\n",
       " (31, 29, 30),\n",
       " (29, 31, 2),\n",
       " (72, 12, 13),\n",
       " (11, 10, 54),\n",
       " (35, 29, 42),\n",
       " (29, 35, 30),\n",
       " (12, 11, 54),\n",
       " (40, 2, 41),\n",
       " (2, 40, 29),\n",
       " (72, 13, 71),\n",
       " (37, 19, 20),\n",
       " (14, 71, 13),\n",
       " (71, 14, 15),\n",
       " (14, 13, 46),\n",
       " (1, 36, 41),\n",
       " (71, 15, 16),\n",
       " (15, 14, 45),\n",
       " (17, 37, 36),\n",
       " (71, 16, 70),\n",
       " (16, 15, 45),\n",
       " (44, 25, 45),\n",
       " (25, 44, 24),\n",
       " (17, 36, 0),\n",
       " (17, 68, 18),\n",
       " (27, 42, 28),\n",
       " (42, 27, 22),\n",
       " (18, 69, 19),\n",
       " (69, 18, 68),\n",
       " (69, 20, 19),\n",
       " (20, 69, 23),\n",
       " (22, 21, 20),\n",
       " (42, 22, 43),\n",
       " (46, 44, 45),\n",
       " (44, 46, 47),\n",
       " (20, 21, 38),\n",
       " (28, 42, 29),\n",
       " (14, 46, 45),\n",
       " (22, 20, 23),\n",
       " (22, 23, 43),\n",
       " (69, 24, 23),\n",
       " (24, 69, 25),\n",
       " (23, 24, 43),\n",
       " (44, 47, 43),\n",
       " (26, 69, 70),\n",
       " (69, 26, 25),\n",
       " (25, 26, 45),\n",
       " (26, 70, 16),\n",
       " (26, 16, 45),\n",
       " (27, 28, 39),\n",
       " (30, 34, 33),\n",
       " (34, 30, 35),\n",
       " (10, 64, 54),\n",
       " (64, 10, 55),\n",
       " (56, 8, 57),\n",
       " (9, 56, 55),\n",
       " (31, 30, 32),\n",
       " (31, 49, 48),\n",
       " (4, 31, 48),\n",
       " (5, 60, 59),\n",
       " (60, 5, 48),\n",
       " (32, 30, 33),\n",
       " (34, 52, 33),\n",
       " (52, 34, 35),\n",
       " (32, 33, 50),\n",
       " (37, 40, 41),\n",
       " (40, 37, 38),\n",
       " (36, 37, 41),\n",
       " (37, 20, 38),\n",
       " (38, 21, 39),\n",
       " (38, 39, 40),\n",
       " (35, 42, 47),\n",
       " (42, 43, 47),\n",
       " (43, 24, 44),\n",
       " (47, 54, 35),\n",
       " (48, 49, 60),\n",
       " (6, 59, 58),\n",
       " (49, 50, 61),\n",
       " (57, 7, 58),\n",
       " (65, 53, 55),\n",
       " (53, 65, 63),\n",
       " (51, 52, 63),\n",
       " (52, 35, 53),\n",
       " (53, 63, 52),\n",
       " (53, 35, 64),\n",
       " (64, 35, 54),\n",
       " (55, 53, 64),\n",
       " (51, 63, 62),\n",
       " (55, 56, 65),\n",
       " (66, 56, 57),\n",
       " (56, 66, 65),\n",
       " (49, 61, 59),\n",
       " (57, 58, 66),\n",
       " (49, 59, 60),\n",
       " (58, 59, 67),\n",
       " (59, 61, 67),\n",
       " (66, 58, 67),\n",
       " (62, 63, 66),\n",
       " (66, 63, 65)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "avgPoints = []\n",
    "for a, b in zip(points1, points2) :\n",
    "    avgPoints.append(((a[0]+b[0])/2 , (a[1]+b[1])/2))\n",
    "avgPoints\n",
    "print((0,0,im1.shape[1],im1.shape[0]))\n",
    "dt = calculateDelaunayTriangles((0,0,im2.shape[1],im2.shape[0]),avgPoints)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space for final output\n",
    "imgMorph = np.zeros(img1.shape, dtype = img1.dtype)\n",
    "\n",
    "# Read triangles from tri.txt\n",
    "# with open(\"./data/images/tri.txt\") as file :\n",
    "    \n",
    "for line in dt :\n",
    "#     x,y,z = line.split()\n",
    "    x = line[0] \n",
    "    y = line[1]\n",
    "    z = line[2]\n",
    "    \n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    z = int(z)\n",
    "\n",
    "    t1 = [points1[x], points1[y], points1[z]]\n",
    "    t2 = [points2[x], points2[y], points2[z]]\n",
    "    t = [ points[x], points[y], points[z] ]\n",
    "\n",
    "    # Morph one triangle at a time.\n",
    "    morphTriangle(img1, img2, imgMorph, t1, t2, t, alpha)\n",
    "\n",
    "\n",
    "# Display Result\n",
    "cv2.imshow(\"Morphed Face\", np.uint8(imgMorph))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오른 귀가 보이는 모습으로의 tri.txt가 되어있음\n",
    "- 따라서 왼쪽 귀가 보이는 얽굴이면 좌우 반전 해줘야 될 것 같음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>cv2.flip(im1, 1)</code>\n",
    "<code>cv2.flip(im2, 1)</code>\n",
    "를 추가해야됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
