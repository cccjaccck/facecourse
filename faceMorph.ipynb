{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FaceMorph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랜드마크 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces 1 dectected:  1\n",
      "Number of faces 2 dectected:  1\n",
      "Number of landmarks 1 :  68\n",
      "Number of landmarks 2 :  68\n"
     ]
    }
   ],
   "source": [
    "import dlib, cv2\n",
    "import numpy as np\n",
    "# from renderFace import renderFace\n",
    "\n",
    "def writeLandmarksToFile(landmarks, landmarksFileName) :\n",
    "    with open(landmarksFileName, 'w') as f:\n",
    "        for p in landmarks.parts() :\n",
    "            f.write(\"%s %s\\n\" %(int(p.x), int(p.y)))\n",
    "            \n",
    "    f.close()\n",
    "    \n",
    "def appendLandmarksToList(landmarks, arr) :\n",
    "    for p in landmarks.parts() :\n",
    "        arr.append((int(p.x), int(p.y)))\n",
    "    \n",
    "\n",
    "    \n",
    "# Landmark model location\n",
    "PREDICTOR_PATH = \"./models/shape_predictor_68_face_landmarks.dat\"\n",
    "\n",
    "# Get the face detector\n",
    "faceDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# The landmark detector is implemented in the shape_predictor class\n",
    "landmarkDetector = dlib.shape_predictor(PREDICTOR_PATH)\n",
    "\n",
    "    \n",
    "    \n",
    "# Read image\n",
    "imageFilename1 = \"./data/images/elsa2.jpg\"\n",
    "imageFilename2 = \"./data/images/yena2.jpg\"\n",
    "im1 = cv2.imread(imageFilename1)\n",
    "im2 = cv2.imread(imageFilename2)\n",
    "im1 = cv2.resize(im1, (600, 600))\n",
    "im2 = cv2.resize(im2, (600, 600))\n",
    "# im1 = cv2.flip(im1, 1)\n",
    "# im2 = cv2.flip(im2, 1)\n",
    "\n",
    "# Detect faces in the image\n",
    "faceRects1 = faceDetector(im1, 0)\n",
    "faceRects2 = faceDetector(im2, 0)\n",
    "print(\"Number of faces 1 dectected: \", len(faceRects1))\n",
    "print(\"Number of faces 2 dectected: \", len(faceRects2))\n",
    "\n",
    "# List to store landmarks of all detected faces\n",
    "landmarksAll1 = []\n",
    "landmarksAll2 = []\n",
    "\n",
    "# 랜드마크 찾기\n",
    "# Loop over all detected face rectangles\n",
    "for i in range(0, len(faceRects1)) :\n",
    "    newRect1 = dlib.rectangle(int(faceRects1[i].left()),\n",
    "                           int(faceRects1[i].top()),\n",
    "                           int(faceRects1[i].right()),\n",
    "                           int(faceRects1[i].bottom()))\n",
    "    newRect2 = dlib.rectangle(int(faceRects2[i].left()),\n",
    "                            int(faceRects2[i].top()),\n",
    "                            int(faceRects2[i].right()),\n",
    "                            int(faceRects2[i].bottom()))\n",
    "    #\n",
    "    # For every face rectangle, run landmarkDectector\n",
    "    landmarks1 = landmarkDetector(im1, newRect1)\n",
    "    landmarks2 = landmarkDetector(im2, newRect2)\n",
    "    # Print number of landmarks\n",
    "    if i==0:\n",
    "        print(\"Number of landmarks 1 : \", len(landmarks1.parts()))\n",
    "        print(\"Number of landmarks 2 : \", len(landmarks1.parts()))\n",
    "        \n",
    "    # Store landmarks for current face\n",
    "    appendLandmarksToList(landmarks1, landmarksAll1)\n",
    "    appendLandmarksToList(landmarks2, landmarksAll2)\n",
    "    \n",
    "#     Draw landmarks on face\n",
    "#     renderFace2(im1, landmarks1)\n",
    "#     renderFace(im2, landmarks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPolyline(im, landmarks, start, end, isClosed=False) :\n",
    "    points = []\n",
    "    for i in range(start, end+1) :\n",
    "        point = [landmarks.part(i).x, landmarks.part(i).y]\n",
    "        points.append(point)\n",
    "        \n",
    "    points = np.array(points, dtype=np.int32)\n",
    "    cv2.polylines(im, [points], isClosed, (255, 200, 0),\n",
    "                 thickness=2, lineType=cv2.LINE_8)\n",
    "    \n",
    "\n",
    "# Use this function for 70-poinst facial lanmark detector model\n",
    "def renderFace(im, landmarks) :\n",
    "    assert(landmarks.num_parts == 68)\n",
    "    drawPolyline(im, landmarks, 0, 16)              # Jaw line\n",
    "    drawPolyline(im, landmarks, 17, 21)             # Left eyebrow\n",
    "    drawPolyline(im, landmarks, 22, 26)             # Right eyebrow\n",
    "    drawPolyline(im, landmarks, 27, 30)             # NOse bridge \n",
    "    drawPolyline(im, landmarks, 30, 35, True)       # Lower nose\n",
    "    drawPolyline(im, landmarks, 36, 41, True)       # Left eye\n",
    "    drawPolyline(im, landmarks, 42, 47, True)       # Right eye\n",
    "    drawPolyline(im, landmarks, 48, 59, True)       # Outer LIp\n",
    "    drawPolyline(im, landmarks, 60, 67, True)       # Inner lip\n",
    "\n",
    "    \n",
    "# Ues this funciton for any model other than \n",
    "# 70 points facial_landmark detctor model\n",
    "def renderFace2(im, landmarks, color=(0, 255, 0), radius=3):\n",
    "    for p in landmarks.parts() :\n",
    "        cv2.circle(im, (p.x, p.y), radius, color, -1)\n",
    "        \n",
    "        \n",
    "def renderFace3(im, landmarks, color=(0, 255, 0), radius=3):\n",
    "    for p in landmarks :\n",
    "        cv2.circle(im, (p[0], p[1]), radius, color, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 임시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarksAll1[17:27] = mouse[0:10]\n",
    "landmarksAll1[36:48] = mouse[10:]\n",
    "renderFace3(im1, landmarksAll1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"im1\", im1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마우스로 눈썹, 눈 포인트 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클릭 좌표 : 268, 190\n",
      "클릭 좌표 : 287, 190\n",
      "클릭 좌표 : 310, 193\n",
      "클릭 좌표 : 333, 200\n",
      "클릭 좌표 : 351, 206\n",
      "클릭 좌표 : 399, 219\n",
      "클릭 좌표 : 415, 218\n",
      "클릭 좌표 : 432, 218\n",
      "클릭 좌표 : 443, 226\n",
      "클릭 좌표 : 452, 232\n",
      "클릭 좌표 : 268, 213\n",
      "클릭 좌표 : 286, 213\n",
      "클릭 좌표 : 316, 220\n",
      "클릭 좌표 : 329, 257\n",
      "클릭 좌표 : 306, 248\n",
      "클릭 좌표 : 282, 235\n",
      "클릭 좌표 : 387, 270\n",
      "클릭 좌표 : 402, 243\n",
      "클릭 좌표 : 433, 245\n",
      "클릭 좌표 : 439, 261\n",
      "클릭 좌표 : 432, 274\n",
      "클릭 좌표 : 410, 279\n",
      "did it\n"
     ]
    }
   ],
   "source": [
    "# 1. 마우스 이벤트 발생시 호출될 함수를 정의합니다. \n",
    "mouse = []\n",
    "def mouse_callback1(event, x, y, flags, param):\n",
    "    l = len(landmarksAll1)\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         if (l==70):\n",
    "#             x = im1.shape[1] - 1\n",
    "#         if (l==71):\n",
    "#             x = 0\n",
    "        print(\"클릭 좌표 : %d, %d\"%(x,y))\n",
    "#         landmarksAll1.append((x,y))\n",
    "        mouse.append((x,y))\n",
    "\n",
    "\n",
    "# img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')  # 2. 마우스 이벤트를 감지할 윈도우를 생성합니다.  \n",
    "\n",
    "\n",
    "# 3. 이름이 image인 윈도우에서 마우스 이벤트가 발생하면 mouse_callback 함수가 호출되게 됩니다. \n",
    "cv2.setMouseCallback('image', mouse_callback1)  \n",
    "\n",
    "\n",
    "cv2.imshow('image',im1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "if len(mouse) == 22:\n",
    "    landmarksAll1[17:27] = mouse[0:10]\n",
    "    landmarksAll1[36:48] = mouse[10:]\n",
    "    print(\"did it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_save = mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 이미지의 얼굴 마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = np.array(landmarksAll1)\n",
    "\n",
    "outline = landmarks[[*range(17), *range(26,16,-1)]]\n",
    "outline2 = np.array(landmarksAll2)[[*range(17), *range(26,16,-1)]]\n",
    "outline = np.array(outline)\n",
    "outline2 = np.array(outline2)\n",
    "cropped_img = np.zeros(im2.shape)\n",
    "base = np.zeros(im1.shape)\n",
    "cv2.fillConvexPoly(cropped_img, cv2.convexHull(outline2), (1.0,1.0,1.0))\n",
    "cv2.fillConvexPoly(base, cv2.convexHull(outline), (1.0,1.0,1.0))\n",
    "\n",
    "cv2.imshow(\"cropped\", cropped_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"cropped\", base)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# out_face = np.ones_like(im2)\n",
    "out_face = np.zeros_like(im2)\n",
    "# out_face = np.copy(im2)\n",
    "# out_face = cv2.cvtColor(im2, cv2.COLOR_RGB2RGBA)\n",
    "mask2 = cropped_img.astype(np.bool)\n",
    "# mask1 = np.invert(mask1)\n",
    "# out_face[:,:,3] = np.zeros_like(out_face[:,:,3])\n",
    "out_face[mask2] = im2[mask2]\n",
    "img2 = out_face\n",
    "# im2 = out_face\n",
    "cv2.imshow(\"cropped\", out_face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_face = np.zeros_like(im1)\n",
    "mask1 = base.astype(np.bool)\n",
    "out_face[mask1] = im1[mask1]\n",
    "img1 = out_face\n",
    "cv2.imshow(\"cropped\", out_face)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_face = np.zeros_like(im1)\n",
    "# mask1_inv = np.invert(mask1)\n",
    "# base_face[mask1_inv] = im1[mask1_inv]\n",
    "# cv2.imshow(\"cropped\", base_face)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 마우스로 포인트 추가 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클릭 좌표 : 391, 182\n",
      "클릭 좌표 : 323, 318\n",
      "클릭 좌표 : 127, 326\n",
      "클릭 좌표 : 428, 266\n"
     ]
    }
   ],
   "source": [
    "# 1. 마우스 이벤트 발생시 호출될 함수를 정의합니다. \n",
    "def mouse_callback1(event, x, y, flags, param):\n",
    "    l = len(landmarksAll1)\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        print(\"클릭 좌표 : %d, %d\"%(x,y))\n",
    "        landmarksAll1.append((x,y))\n",
    "\n",
    "cv2.namedWindow('image')  # 2. 마우스 이벤트를 감지할 윈도우를 생성합니다.  \n",
    "\n",
    "# 3. 이름이 image인 윈도우에서 마우스 이벤트가 발생하면 mouse_callback 함수가 호출되게 됩니다. \n",
    "cv2.setMouseCallback('image', mouse_callback1)  \n",
    "cv2.imshow('image',im1)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클릭 좌표 : 435, 218\n",
      "클릭 좌표 : 337, 449\n",
      "클릭 좌표 : 113, 421\n",
      "클릭 좌표 : 560, 503\n"
     ]
    }
   ],
   "source": [
    "# 2번 사진\n",
    "def mouse_callback2(event, x, y, flags, param):\n",
    "    l = len(landmarksAll2)\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "#         if (l==70):\n",
    "#             x = im2.shape[1] - 1\n",
    "#         if (l==71):\n",
    "#             x = 0\n",
    "        print(\"클릭 좌표 : %d, %d\"%(x,y))\n",
    "        landmarksAll2.append((x,y))\n",
    "\n",
    "\n",
    "# img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')  # 2. 마우스 이벤트를 감지할 윈도우를 생성합니다.  \n",
    "\n",
    "\n",
    "# 3. 이름이 image인 윈도우에서 마우스 이벤트가 발생하면 mouse_callback 함수가 호출되게 됩니다. \n",
    "cv2.setMouseCallback('image', mouse_callback2)  \n",
    "\n",
    "\n",
    "cv2.imshow('image',im2)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 72)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarksAll1), len(landmarksAll2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지의 가장자리 8개 추가 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1 2 3 \n",
    "# 8   4\n",
    "# 7 6 5\n",
    "##\n",
    "for arr, im in [(landmarksAll1, im1), (landmarksAll2, im2)] :\n",
    "    arr.append((0, 0))\n",
    "    arr.append(((im.shape[1]-1)/2, 0))\n",
    "    arr.append((im.shape[1]-1, 0))\n",
    "    arr.append((im.shape[1]-1, (im.shape[0]-1)/2))\n",
    "    arr.append((im.shape[1]-1, im.shape[0]-1))\n",
    "    arr.append(((im.shape[1]-1)/2, im.shape[0]-1))\n",
    "    arr.append((0, im.shape[0]-1))\n",
    "    arr.append((0, (im.shape[0]-1)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 76)"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarksAll1), len(landmarksAll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (299.5, 0),\n",
       " (599, 0),\n",
       " (599, 299.5),\n",
       " (599, 599),\n",
       " (299.5, 599),\n",
       " (0, 599),\n",
       " (0, 299.5)]"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarksAll1[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (299.5, 0),\n",
       " (599, 0),\n",
       " (599, 299.5),\n",
       " (599, 599),\n",
       " (299.5, 599),\n",
       " (0, 599),\n",
       " (0, 299.5)]"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarksAll2[-8:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 Morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "# Read points from text file\n",
    "def readPoints(path) :\n",
    "    # Create an array of points.\n",
    "    points = [];\n",
    "    # Read points\n",
    "    with open(path) as file :\n",
    "        for line in file :\n",
    "            x, y = line.split()\n",
    "            points.append((int(x), int(y)))\n",
    "\n",
    "    return points\n",
    "\n",
    "# Apply affine transform calculated using srcTri and dstTri to src and\n",
    "# output an image of size.\n",
    "def applyAffineTransform(src, srcTri, dstTri, size) :\n",
    "    \n",
    "    # Given a pair of triangles, find the affine transform.\n",
    "    warpMat = cv2.getAffineTransform( np.float32(srcTri), np.float32(dstTri) )\n",
    "    \n",
    "    # Apply the Affine Transform just found to the src image\n",
    "    dst = cv2.warpAffine( src, warpMat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def morphTriangle(img1, img2, img, t1, t2, t, alpha) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t]))\n",
    "\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = []\n",
    "    t2Rect = []\n",
    "    tRect = []\n",
    "\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        tRect.append(((t[i][0] - r[0]),(t[i][1] - r[1])))\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r[3], r[2], 3), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(tRect), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    img2Rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]\n",
    "\n",
    "    size = (r[2], r[3])\n",
    "    warpImage1 = applyAffineTransform(img1Rect, t1Rect, tRect, size)\n",
    "    warpImage2 = applyAffineTransform(img2Rect, t2Rect, tRect, size)\n",
    "    \n",
    "\n",
    "    # Alpha blend rectangular patches\n",
    "    imgRect = (1.0 - alpha) * warpImage1 + alpha * warpImage2\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    try :\n",
    "        img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * ( 1 - mask ) + imgRect * mask\n",
    "    except :\n",
    "        print(( 1 - mask ).shape, \"띠띠\")\n",
    "        print(img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]].shape, \"빵빵\")\n",
    "        raise Exception\n",
    "\n",
    "    return mask\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if a point is inside a rectangle\n",
    "def rectContains(rect, point) :\n",
    "    if point[0] < rect[0] :\n",
    "        return False\n",
    "    elif point[1] < rect[1] :\n",
    "        return False\n",
    "    elif point[0] > rect[2] :\n",
    "        return False\n",
    "    elif point[1] > rect[3] :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def calculateDelaunayTriangles(rect, points):\n",
    "    # Create subdiv\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "   \n",
    "    # Insert points into subdiv\n",
    "    for p in points:\n",
    "        subdiv.insert((p[0], p[1]))\n",
    "\n",
    "   \n",
    "    # List of triangles. Each triangle is a list of 3 points ( 6 numbers )\n",
    "    triangleList = subdiv.getTriangleList()\n",
    "\n",
    "    # Find the indices of triangles in the points array\n",
    "\n",
    "    delaunayTri = []\n",
    "    \n",
    "    for t in triangleList:\n",
    "        pt = []\n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])        \n",
    "        \n",
    "        if rectContains(rect, pt1) and rectContains(rect, pt2) and rectContains(rect, pt3):\n",
    "            ind = []\n",
    "            for j in range(0, 3):\n",
    "                for k in range(0, len(points)):                    \n",
    "                    if(abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0):\n",
    "                        ind.append(k)                            \n",
    "            if len(ind) == 3:                                                \n",
    "                delaunayTri.append((ind[0], ind[1], ind[2]))\n",
    "        \n",
    "\n",
    "    \n",
    "    return delaunayTri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.9\n",
    "\n",
    "# Convert Mat to float data type\n",
    "img1 = np.float32(img1)\n",
    "img2 = np.float32(img2)\n",
    "\n",
    "# Read array of corresponding points\n",
    "#     points1 = readPoints(filename1 + '.txt')\n",
    "#     points2 = readPoints(filename2 + '.txt')\n",
    "points1 = landmarksAll1\n",
    "points2 = landmarksAll2\n",
    "points = [];\n",
    "\n",
    "# Compute weighted average point coordinates\n",
    "for i in range(0, len(points1)):\n",
    "    x = ( 1 - alpha ) * points1[i][0] + alpha * points2[i][0]\n",
    "    y = ( 1 - alpha ) * points1[i][1] + alpha * points2[i][1]\n",
    "    points.append((x,y))\n",
    "\n",
    "    \n",
    "avgPoints = []\n",
    "for a, b in zip(points1, points2) :\n",
    "    avgPoints.append(((a[0]+b[0])/2 , (a[1]+b[1])/2))\n",
    "avgPoints\n",
    "# print((0,0,im1.shape[1],im1.shape[0]))\n",
    "dt = calculateDelaunayTriangles((0,0,im2.shape[1],im2.shape[0]),avgPoints)\n",
    "\n",
    "\n",
    "# Allocate space for final output\n",
    "imgMorph = np.zeros(img1.shape, dtype = img1.dtype)\n",
    "\n",
    "for line in dt :\n",
    "    x = line[0] \n",
    "    y = line[1]\n",
    "    z = line[2]\n",
    "    \n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    z = int(z)\n",
    "\n",
    "    t1 = [points1[x], points1[y], points1[z]]\n",
    "    t2 = [points2[x], points2[y], points2[z]]\n",
    "    t = [ points[x], points[y], points[z] ]\n",
    "\n",
    "    # Morph one triangle at a time.\n",
    "    morphTriangle(img1, img2, imgMorph, t1, t2, t, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 600, 3)"
      ]
     },
     "execution_count": 700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgMorph.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Result\n",
    "cv2.imshow(\"Morphed Face\", np.uint8(imgMorph))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"./morp.png\", imgMorph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 스왑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 68\n",
      "68 68\n"
     ]
    }
   ],
   "source": [
    "multiDisplay(swap(imgMorph, im1, points, points1),swap(imgMorph, im2, points, points2), alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiDisplay(img1, img2, alpha) :\n",
    "    img = cv2.hconcat([img1,img2])\n",
    "    cv2.imshow((\"alpha = \"+str(alpha)), img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warps and alpha blends triangular regions from img1 and img2 to img\n",
    "def warpTriangle(img1, img2, t1, t2) :\n",
    "\n",
    "    # Find bounding rectangle for each triangle\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "\n",
    "    # Offset points by left top corner of the respective rectangles\n",
    "    t1Rect = [] \n",
    "    t2Rect = []\n",
    "    t2RectInt = []\n",
    "\n",
    "    for i in range(0, 3):\n",
    "        t1Rect.append(((t1[i][0] - r1[0]),(t1[i][1] - r1[1])))\n",
    "        t2Rect.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "        t2RectInt.append(((t2[i][0] - r2[0]),(t2[i][1] - r2[1])))\n",
    "\n",
    "\n",
    "    # Get mask by filling triangle\n",
    "    mask = np.zeros((r2[3], r2[2], 3), dtype = np.float32)\n",
    "    cv2.fillConvexPoly(mask, np.int32(t2RectInt), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "    # Apply warpImage to small rectangular patches\n",
    "    img1Rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    #img2Rect = np.zeros((r2[3], r2[2]), dtype = img1Rect.dtype)\n",
    "    \n",
    "    size = (r2[2], r2[3])\n",
    "\n",
    "    img2Rect = applyAffineTransform(img1Rect, t1Rect, t2Rect, size)\n",
    "    \n",
    "    img2Rect = img2Rect * mask\n",
    "\n",
    "    # Copy triangular region of the rectangular patch to the output image\n",
    "    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] * ( (1.0, 1.0, 1.0) - mask )\n",
    "     \n",
    "    img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] = img2[r2[1]:r2[1]+r2[3], r2[0]:r2[0]+r2[2]] + img2Rect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def swap(img1, img2, points_src, points_dst) :\n",
    "    \n",
    "#     img1 = imgMorph;\n",
    "#     img2 = im1;\n",
    "    img1Warped = np.copy(img2);    \n",
    "\n",
    "    # Read array of corresponding points\n",
    "    points2 = points_dst[:-8]\n",
    "    points1 = points_src[:-8]\n",
    "    print(len(points1), len(points2))\n",
    "    \n",
    "    # Find convex hull\n",
    "    hull1 = []\n",
    "    hull2 = []\n",
    "\n",
    "    hullIndex = cv2.convexHull(np.array(points2), returnPoints = False)\n",
    "\n",
    "    for i in range(0, len(hullIndex)):\n",
    "        hull1.append(points1[int(hullIndex[i])])\n",
    "        hull2.append(points2[int(hullIndex[i])])\n",
    "\n",
    "\n",
    "    # Find delanauy traingulation for convex hull points\n",
    "    sizeImg2 = img2.shape    \n",
    "    rect = (0, 0, sizeImg2[1], sizeImg2[0])\n",
    "\n",
    "    dt = calculateDelaunayTriangles(rect, hull2)\n",
    "\n",
    "    if len(dt) == 0:\n",
    "        quit()\n",
    "\n",
    "    # Apply affine transformation to Delaunay triangles\n",
    "    for i in range(0, len(dt)):\n",
    "        t1 = []\n",
    "        t2 = []\n",
    "\n",
    "        #get points for img1, img2 corresponding to the triangles\n",
    "        for j in range(0, 3):\n",
    "            t1.append(hull1[dt[i][j]])\n",
    "            t2.append(hull2[dt[i][j]])\n",
    "\n",
    "        warpTriangle(img1, img1Warped, t1, t2)\n",
    "\n",
    "\n",
    "    # Calculate Mask\n",
    "    hull8U = []\n",
    "    for i in range(0, len(hull2)):\n",
    "        hull8U.append((hull2[i][0], hull2[i][1]))\n",
    "\n",
    "    mask = np.zeros(img2.shape, dtype = img2.dtype)  \n",
    "\n",
    "    cv2.fillConvexPoly(mask, np.int32(hull8U), (255, 255, 255))\n",
    "\n",
    "    r = cv2.boundingRect(np.float32([hull2]))    \n",
    "\n",
    "    center = ((r[0]+int(r[2]/2), r[1]+int(r[3]/2)))\n",
    "\n",
    "\n",
    "    # Clone seamlessly.\n",
    "    output = cv2.seamlessClone(np.uint8(img1Warped), img2, mask, center, cv2.NORMAL_CLONE)\n",
    "\n",
    "#     cv2.imshow(\"Face Swapped\", output)\n",
    "#     cv2.waitKey(0)\n",
    "\n",
    "#     cv2.destroyAllWindows()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
